{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from plot_utils import extract_measures, extract_utterance, get_distributions, get_x_positions, order_lists\n",
    "\n",
    "# from plot_graphs import plot_reward  \n",
    "\n",
    "sns.set()\n",
    "# plt.set\n",
    "# plt.figure.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dir_ = 'final/logs/'\n",
    "\n",
    "filenames = {\n",
    "    'self_both': 'final/new/log_20191102_173823final_fixed_disable-prosocial.log',\n",
    "    'prosoc_both': 'final/new/log_20191101_231223final_fixed.log',\n",
    "    'prosoc_linguistic': 'final/logs/log_20191029_191658final_disable-proposal.log' # old\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_reward(logfile, min_y, max_y, title, max_x, labels=None):\n",
    "    \"\"\"\n",
    "    logfiles separated by : are combined\n",
    "    logfiles separated by , go in separate plots\n",
    "    (: binds tighter than ,)\n",
    "    \"\"\"\n",
    "    logfiles = logfile\n",
    "    split_logfiles = logfiles.split(',')\n",
    "    if labels:\n",
    "        labels = labels.split(',')\n",
    "\n",
    "    for j, logfile_groups in enumerate(split_logfiles):\n",
    "        epoch = []\n",
    "        reward = []\n",
    "        test_reward_0 = []\n",
    "        test_reward_1 = []\n",
    "        test_reward = []\n",
    "        for logfile in logfile_groups.split(':'):\n",
    "            with open(logfile, 'r') as f:\n",
    "                for n, line in enumerate(f):\n",
    "                    if n == 0:\n",
    "                        print(logfile, line)\n",
    "                        continue  # skip first line\n",
    "                    line = line.strip()\n",
    "                    if line == '':\n",
    "                        continue\n",
    "                    d = json.loads(line)\n",
    "                    if max_x is not None and d['episode'] > max_x:\n",
    "                        continue\n",
    "                    epoch.append(int(d['episode']))\n",
    "                    reward.append(float(d['avg_reward_0']))\n",
    "                    test_reward_0.append(float(d['agent0_test_reward']))\n",
    "                    test_reward_1.append(float(d['agent1_test_reward']))\n",
    "                    if 'test_reward' in d:\n",
    "                        test_reward.append(d['test_reward'])\n",
    "\n",
    "        while len(epoch) > 200:\n",
    "            new_epoch = []\n",
    "            new_reward = []\n",
    "            new_test_reward = []\n",
    "            new_test_reward_0 = []\n",
    "            new_test_reward_1 = []\n",
    "\n",
    "            for n in range(len(epoch) // 2):\n",
    "                r = (reward[n * 2] + reward[n * 2 + 1]) / 2\n",
    "                e = (epoch[n * 2] + epoch[n * 2 + 1]) // 2\n",
    "                new_epoch.append(e)\n",
    "                new_reward.append(r)\n",
    "                new_test_reward_0.append(test_reward_0[n * 2])\n",
    "                new_test_reward_1.append(test_reward_1[n * 2])\n",
    "                if len(test_reward) > 0:\n",
    "                    rt = (test_reward[n * 2] + test_reward[n * 2 + 1]) / 2\n",
    "                    new_test_reward.append(rt)\n",
    "            epoch = new_epoch\n",
    "            reward = new_reward\n",
    "            test_reward = new_test_reward\n",
    "            test_reward_0 = new_test_reward_0\n",
    "            test_reward_1 = new_test_reward_1\n",
    "\n",
    "        if min_y is None:\n",
    "            min_y = 0\n",
    "        if max_y is not None:\n",
    "            plt.ylim([min_y, max_y])\n",
    "        suffix = ''\n",
    "        if len(split_logfiles) > 0:\n",
    "            suffix = ' %s' % (j + 1)\n",
    "        if len(test_reward) > 0:\n",
    "            label = labels[j] + ' ' if labels else ''\n",
    "            plt.plot(np.array(epoch) / 1000, reward, label=label + 'train' + suffix)\n",
    "            plt.plot(np.array(epoch) / 1000, test_reward, label=label + 'test' + suffix)\n",
    "            plt.plot(np.array(epoch) / 1000, test_reward_0, label=label + 'test 0' + suffix)\n",
    "            plt.plot(np.array(epoch) / 1000, test_reward_1, label=label + 'test 1' + suffix)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            plt.plot(np.array(epoch) / 1000, reward, label='reward' + suffix)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.xlabel('Episodes of 128 games (thousands)')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.legend()\n",
    "    print('saving file')\n",
    "    plt.savefig('/tmp/out-reward.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_reward(filenames['self_both'], 0, 1, 'Final', 200000, 'final,final_memory-comp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joint_reward_success(**kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    FOR TABLE 2\n",
    "    \n",
    "    keys:\n",
    "    self_proposal, self_linguistic, self_both, self_none,\n",
    "    prosoc_proposal, prosoc_linguistic, prosoc_both, prosoc_none\n",
    "    \n",
    "    values:\n",
    "    filenames\n",
    "    \n",
    "    Joint reward success and average number of turns taken for paired agents negotiating\n",
    "    with random game termination, varying the agent reward scheme and communication channel.\n",
    "    \"\"\"\n",
    "    \n",
    "    from_paper = {'self_proposal': 0.87, 'self_linguistic': 0.75, 'self_both': 0.87, 'self_none': 0.77,\n",
    "                  'prosoc_proposal': 0.93,  'prosoc_linguistic': 0.99, 'prosoc_both': 0.92, 'prosoc_none': 0.95}\n",
    "    \n",
    "    socialities = ['self', 'prosoc']\n",
    "    channels = ['proposal', 'linguistic', 'both', 'none']\n",
    "    data = {}\n",
    "    \n",
    "    for sociality in socialities:\n",
    "        for channel in channels:\n",
    "            key = sociality + '_' + channel\n",
    "            filename = kwargs.pop(key, None)\n",
    "            \n",
    "            if filename:\n",
    "                extracted = extract_measures(filenames[key], ['test_reward'])\n",
    "                joint_reward = np.mean(extracted['test_reward'])\n",
    "\n",
    "            else:\n",
    "                joint_reward = -1\n",
    "            data[key] = {'joint_reward': joint_reward}\n",
    "            \n",
    "    for sociality in socialities:\n",
    "        for channel in channels:\n",
    "            key = sociality + '_' + channel\n",
    "            print('\\tour:       {}'.format(data[key]['joint_reward']))\n",
    "            print('\\tfrom paper: {}'.format(from_paper[key]))\n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joint_reward_success(**filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_training_curve(filename, min_y=0, max_y=1, title='', max_x=200000, labels=None):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    epoch = []\n",
    "    test_reward_0 = []\n",
    "    test_reward_1 = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for n, line in enumerate(f):\n",
    "            if n == 0:\n",
    "                continue  # skip first line\n",
    "            line = line.strip()\n",
    "            if line == '':\n",
    "                continue\n",
    "            d = json.loads(line)\n",
    "            if max_x is not None and d['episode'] > max_x:\n",
    "                continue\n",
    "            epoch.append(int(d['episode']))\n",
    "            test_reward_0.append(float(d['agent0_test_reward']))\n",
    "            test_reward_1.append(float(d['agent1_test_reward']))\n",
    "                \n",
    "        while len(epoch) > 200:\n",
    "            new_epoch = []\n",
    "            new_test_reward_0 = []\n",
    "            new_test_reward_1 = []\n",
    "\n",
    "            for n in range(len(epoch) // 2):\n",
    "                r = (reward[n * 2] + reward[n * 2 + 1]) / 2\n",
    "                e = (epoch[n * 2] + epoch[n * 2 + 1]) // 2\n",
    "                new_epoch.append(e)\n",
    "                new_test_reward_0.append(test_reward_0[n * 2])\n",
    "                new_test_reward_1.append(test_reward_1[n * 2])\n",
    "\n",
    "            epoch = new_epoch\n",
    "            test_reward_0 = new_test_reward_0\n",
    "            test_reward_1 = new_test_reward_1\n",
    "\n",
    "        if min_y is None:\n",
    "            min_y = 0\n",
    "        if max_y is not None:\n",
    "            plt.ylim([min_y, max_y])\n",
    "        suffix = ''\n",
    "        label = labels[j] + ' ' if labels else ''\n",
    "        plt.plot(np.array(epoch) / 1000, test_reward_0, label='test 0' + suffix)\n",
    "        plt.plot(np.array(epoch) / 1000, test_reward_1, label='test 1' + suffix)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.xlabel('Episodes of 128 games (thousands)')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.legend()\n",
    "#     print('saving file')\n",
    "#     plt.savefig('/tmp/out-reward.png')\n",
    "\n",
    "def training_curves(filenames):\n",
    "    \"\"\"\n",
    "    FOR FIGURE 2a\n",
    "    \n",
    "    Training curves for SELF-INTERESTED agents learning to negotiate under the various com- munication channels.\n",
    "    \"\"\"\n",
    "    \n",
    "    channels = ['proposal', 'linguistic', 'both', 'none']\n",
    "    \n",
    "    for channel in channels:\n",
    "        key = 'self_{}'.format(channel)\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_training_curve(filenames['self_both'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_utterance(distribution, turn, vocab_len=10, utter_len=6):\n",
    "    labels = [str(i) for i in range(utter_len)]\n",
    "    \n",
    "    x = np.arange(utter_len)\n",
    "    width = 4\n",
    "    positions = get_x_positions(vocab_len, utter_len, width=width, outer_width=2).T\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    reacts = []\n",
    "    \n",
    "    for i in range(vocab_len):\n",
    "        values = distribution[turn, :, i]\n",
    "        l = positions[i]\n",
    "        print('lens', len(l), values.shape)\n",
    "        reacts.append(ax.bar(l, values, width, label=str(i)))\n",
    "    ax.legend()\n",
    "        \n",
    "    def autolabel(rects):\n",
    "        \"\"\"\n",
    "        Attach a text label above each bar in *rects*, displaying its height.\n",
    "        from: https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n",
    "        \"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "            \n",
    "    ax.set_ylabel('Occurance')\n",
    "    ax.set_title('Symbols distribution in position')\n",
    "#     ax.set_xticks(np.arange(labels))\n",
    "    ax.set_xticklabels(labels)\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "def unigram_statistics(filenames):\n",
    "    \"\"\"\n",
    "    FOR FIGURE 3a\n",
    "    \n",
    "    Unigram statistics of symbol usage broken down by turn and by position within the utterance\n",
    "    for prosocial agents communicating via the linguistic channel.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted = extract_utterance(filenames['prosoc_both'])\n",
    "distribution = get_distributions(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_utterance(np.array(distribution), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_statistics(filenames):\n",
    "    \"\"\"\n",
    "    FOR FIGURE 3b\n",
    "    \n",
    "    Bigram counts for prosocial agents communicating via the linguistic channel, sorted by frequency.\n",
    "    \"\"\"\n",
    "    filename = filenames['prosoc_linguistic']\n",
    "    extracted = extract_utterance(filename)\n",
    "    extracted_a = extracted[::2]\n",
    "    extracted_b = extracted[1::2]\n",
    "    extracted_a = np.array([list(map(str, msg)) for sublist in extracted_a for msg in sublist])\n",
    "    extracted_b = np.array([list(map(str, msg)) for sublist in extracted_b for msg in sublist])\n",
    "\n",
    "    bigrams_a = []\n",
    "    bigrams_b = []\n",
    "    for i in range(extracted_a.shape[1] - 1):\n",
    "        new_bigrams_a = list(np.core.defchararray.add(extracted_a[:, i], extracted_a[:, i + 1]))\n",
    "        new_bigrams_b = list(np.core.defchararray.add(extracted_b[:, i], extracted_b[:, i + 1]))\n",
    "        bigrams_a += new_bigrams_a\n",
    "        bigrams_b += new_bigrams_b\n",
    "\n",
    "    unique, counts = np.unique(bigrams_b, return_counts=True)\n",
    "    counts, unique = order_lists(counts, unique)\n",
    "    x = np.arange(len(counts))\n",
    "    plt.bar(x, counts)\n",
    "\n",
    "bigram_statistics(filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
